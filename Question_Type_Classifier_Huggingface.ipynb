{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMrPOX_RNngc"
      },
      "source": [
        "# Question Type Classifier Training\n",
        "\n",
        "This notebook was derived from the Huggingface example here: https://huggingface.co/transformers/custom_datasets.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFgeVxIgNAlO",
        "outputId": "10f52ed1-76c4-4d00-cbc6-54db65206920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 37.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 37.2 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 30.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.6 transformers-4.17.0\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-1.18.4-py3-none-any.whl (312 kB)\n",
            "\u001b[K     |████████████████████████████████| 312 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.63.0)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n",
            "\u001b[K     |████████████████████████████████| 134 kB 40.2 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 45.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 46.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 47.4 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 37.9 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 51.9 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-1.18.4 frozenlist-1.3.0 fsspec-2022.2.0 multidict-6.0.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install pandas\n",
        "!pip install sklearn\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFzLRs2sNemd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "240f5284-ba09-4f17-fb20-8a95dbdd88c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import DistilBertTokenizerFast     #docs: https://huggingface.co/docs/transformers/model_doc/distilbert#transformers.DistilBertTokenizerFast\n",
        "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBUZY6UPNGxI",
        "outputId": "c772e9e4-0843-4b0a-e586-d6d45df4cc77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/xdrive\n"
          ]
        }
      ],
      "source": [
        "# Read in the data from the CSV file\n",
        "# https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/xdrive', force_remount=True)\n",
        "df = pd.read_csv(\"/content/xdrive/MyDrive/qcat_huggingface/data_4.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FILTER THE DATA\n",
        "df = df[~df['best_guess_label'].isnull()] # trim out all rows without a label\n",
        "\n",
        "# remove classes that have less instances than some threshold\n",
        "# threshold = 5\n",
        "# col = 'best_guess_label'\n",
        "# counts = df[col].value_counts()\n",
        "# df = df.loc[df[col].isin(counts[counts > threshold].index), :]\n",
        "\n",
        "labeledData = df\n",
        "\n",
        "# FILTER: keep just the selected labels\n",
        "# keep_list = ['qualitative_property_retrieval', 'opinion']\n",
        "# labeledData = labeledData.loc[df['best_guess_label'].isin(keep_list)]\n",
        "\n",
        "# FILTER: leave out the selected labels\n",
        "#filter_out_list = [\"opinion\", \"causal_explanation\"]\n",
        "#labeledData = labeledData.loc[~df['best_guess_label'].isin(filter_out_list)]\n",
        "\n",
        "labelColumn = 'best_guess_label'\n",
        "#labelColumn = 'parent_label'\n",
        "\n",
        "# get lists of text and labels\n",
        "all_questions = labeledData[\"question\"].tolist()\n",
        "#all_labels = labeledData[\"best_guess_label\"].tolist()  # use child class labels\n",
        "all_labels = labeledData[labelColumn].tolist()          #use parent class labels\n",
        "\n",
        "# sanity check\n",
        "assert(len(all_questions) == len(all_labels))\n",
        "print(set(all_labels))\n",
        "print(\"NUM CLASSES: \" , len(set(all_labels)))\n",
        "print(\"NUM QUESTIONS: \", len(all_questions))\n",
        "labeledData.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "Mi2eVB3zJSvh",
        "outputId": "aaf5bdbf-04e5-4cac-9894-bd46d3069714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'set_difference', 'boolean_or', 'boolean_and', 'boolean_retrieval', 'set_retrieval', 'range', 'counting', 'opinion', 'average', 'set_property_satisfaction', 'standard_deviation', 'set_intersection', 'causal_explanation', 'mode', 'set_union', 'qualitative_property_retrieval', 'numeric_comparison', 'mathematical_comparison', 'qualitative_property_multihop_retrieval', 'qualitative_comparison', 'numeric_retrieval', 'correlation', 'superlative', 'arithmetic', 'definitional', 'datetime_comparison', 'median', 'datetime_retrieval'}\n",
            "NUM CLASSES:  28\n",
            "NUM QUESTIONS:  858\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        info                                           question  \\\n",
              "0    break_0  what flights are available tomorrow from denve...   \n",
              "1    break_1  show me the afternoon flights from washington ...   \n",
              "2    break_2      show me the flights from atlanta to baltimore   \n",
              "3    break_3  i want a flight from houston to memphis on tue...   \n",
              "4    break_4  what are the cheapest one way flights from atl...   \n",
              "5    break_5  what ground transportation is available from t...   \n",
              "6    break_6  flight information from san francisco to pitts...   \n",
              "7    break_7  what flights are available from san francisco ...   \n",
              "8    break_9  i'm traveling from boston to atlanta and i'd l...   \n",
              "9   break_11                                  what does ff mean   \n",
              "10  break_12  well i'll try last time tell me the kind of ai...   \n",
              "11  break_13          show me the flights from dallas to boston   \n",
              "12  break_14        i need a flight from philadelphia to dallas   \n",
              "13  break_15  what is the round trip first class fare on uni...   \n",
              "14  break_16  i'd like also to book a one way flight from pi...   \n",
              "15  break_17  find me the cheapest one way fare i can get fr...   \n",
              "16  break_18            flights from baltimore to san francisco   \n",
              "17  break_19  i want to fly from baltimore to dallas round trip   \n",
              "18  break_20    what are all the flights into atlanta's airport   \n",
              "19  break_21    show me the flights from philadelphia to dallas   \n",
              "\n",
              "                           best_guess_label  parent_label  \n",
              "0                 set_property_satisfaction    comparison  \n",
              "1                 set_property_satisfaction    comparison  \n",
              "2                 set_property_satisfaction    comparison  \n",
              "3            qualitative_property_retrieval     retrieval  \n",
              "4                               superlative    comparison  \n",
              "5   qualitative_property_multihop_retrieval     retrieval  \n",
              "6            qualitative_property_retrieval     retrieval  \n",
              "7                 set_property_satisfaction    comparison  \n",
              "8   qualitative_property_multihop_retrieval     retrieval  \n",
              "9                              definitional  definitional  \n",
              "10  qualitative_property_multihop_retrieval     retrieval  \n",
              "11                set_property_satisfaction    comparison  \n",
              "12           qualitative_property_retrieval     retrieval  \n",
              "13                        numeric_retrieval     retrieval  \n",
              "14                              superlative    comparison  \n",
              "15                              superlative    comparison  \n",
              "16                set_property_satisfaction    comparison  \n",
              "17           qualitative_property_retrieval     retrieval  \n",
              "18                            set_retrieval     retrieval  \n",
              "19                set_property_satisfaction    comparison  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a84e2cc7-9202-4296-92f1-66e205a3ac9c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>info</th>\n",
              "      <th>question</th>\n",
              "      <th>best_guess_label</th>\n",
              "      <th>parent_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>break_0</td>\n",
              "      <td>what flights are available tomorrow from denve...</td>\n",
              "      <td>set_property_satisfaction</td>\n",
              "      <td>comparison</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>break_1</td>\n",
              "      <td>show me the afternoon flights from washington ...</td>\n",
              "      <td>set_property_satisfaction</td>\n",
              "      <td>comparison</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>break_2</td>\n",
              "      <td>show me the flights from atlanta to baltimore</td>\n",
              "      <td>set_property_satisfaction</td>\n",
              "      <td>comparison</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>break_3</td>\n",
              "      <td>i want a flight from houston to memphis on tue...</td>\n",
              "      <td>qualitative_property_retrieval</td>\n",
              "      <td>retrieval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>break_4</td>\n",
              "      <td>what are the cheapest one way flights from atl...</td>\n",
              "      <td>superlative</td>\n",
              "      <td>comparison</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>break_5</td>\n",
              "      <td>what ground transportation is available from t...</td>\n",
              "      <td>qualitative_property_multihop_retrieval</td>\n",
              "      <td>retrieval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>break_6</td>\n",
              "      <td>flight information from san francisco to pitts...</td>\n",
              "      <td>qualitative_property_retrieval</td>\n",
              "      <td>retrieval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>break_7</td>\n",
              "      <td>what flights are available from san francisco ...</td>\n",
              "      <td>set_property_satisfaction</td>\n",
              "      <td>comparison</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>break_9</td>\n",
              "      <td>i'm traveling from boston to atlanta and i'd l...</td>\n",
              "      <td>qualitative_property_multihop_retrieval</td>\n",
              "      <td>retrieval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>break_11</td>\n",
              "      <td>what does ff mean</td>\n",
              "      <td>definitional</td>\n",
              "      <td>definitional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>break_12</td>\n",
              "      <td>well i'll try last time tell me the kind of ai...</td>\n",
              "      <td>qualitative_property_multihop_retrieval</td>\n",
              "      <td>retrieval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>break_13</td>\n",
              "      <td>show me the flights from dallas to boston</td>\n",
              "      <td>set_property_satisfaction</td>\n",
              "      <td>comparison</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>break_14</td>\n",
              "      <td>i need a flight from philadelphia to dallas</td>\n",
              "      <td>qualitative_property_retrieval</td>\n",
              "      <td>retrieval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>break_15</td>\n",
              "      <td>what is the round trip first class fare on uni...</td>\n",
              "      <td>numeric_retrieval</td>\n",
              "      <td>retrieval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>break_16</td>\n",
              "      <td>i'd like also to book a one way flight from pi...</td>\n",
              "      <td>superlative</td>\n",
              "      <td>comparison</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>break_17</td>\n",
              "      <td>find me the cheapest one way fare i can get fr...</td>\n",
              "      <td>superlative</td>\n",
              "      <td>comparison</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>break_18</td>\n",
              "      <td>flights from baltimore to san francisco</td>\n",
              "      <td>set_property_satisfaction</td>\n",
              "      <td>comparison</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>break_19</td>\n",
              "      <td>i want to fly from baltimore to dallas round trip</td>\n",
              "      <td>qualitative_property_retrieval</td>\n",
              "      <td>retrieval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>break_20</td>\n",
              "      <td>what are all the flights into atlanta's airport</td>\n",
              "      <td>set_retrieval</td>\n",
              "      <td>retrieval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>break_21</td>\n",
              "      <td>show me the flights from philadelphia to dallas</td>\n",
              "      <td>set_property_satisfaction</td>\n",
              "      <td>comparison</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a84e2cc7-9202-4296-92f1-66e205a3ac9c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a84e2cc7-9202-4296-92f1-66e205a3ac9c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a84e2cc7-9202-4296-92f1-66e205a3ac9c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count how many of each label are in the dataset\n",
        "labeledData[labelColumn].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtBQfz0ei3n_",
        "outputId": "4ce79dbc-b685-486e-8118-17527f524a00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "qualitative_property_retrieval             105\n",
              "opinion                                     57\n",
              "superlative                                 56\n",
              "boolean_retrieval                           45\n",
              "set_property_satisfaction                   43\n",
              "causal_explanation                          40\n",
              "definitional                                38\n",
              "numeric_retrieval                           37\n",
              "numeric_comparison                          35\n",
              "qualitative_comparison                      32\n",
              "boolean_and                                 30\n",
              "boolean_or                                  30\n",
              "datetime_retrieval                          28\n",
              "arithmetic                                  27\n",
              "set_union                                   25\n",
              "set_retrieval                               24\n",
              "qualitative_property_multihop_retrieval     23\n",
              "set_intersection                            21\n",
              "set_difference                              20\n",
              "datetime_comparison                         20\n",
              "average                                     20\n",
              "mode                                        20\n",
              "correlation                                 16\n",
              "standard_deviation                          15\n",
              "counting                                    13\n",
              "mathematical_comparison                     13\n",
              "median                                      13\n",
              "range                                       12\n",
              "Name: best_guess_label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vV4g3SJTTIVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e517645-2b99-4954-be4c-d30aad8f3d4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'set_difference': 0, 'boolean_or': 1, 'boolean_and': 2, 'boolean_retrieval': 3, 'set_retrieval': 4, 'range': 5, 'counting': 6, 'opinion': 7, 'average': 8, 'set_property_satisfaction': 9, 'standard_deviation': 10, 'set_intersection': 11, 'causal_explanation': 12, 'mode': 13, 'set_union': 14, 'qualitative_property_retrieval': 15, 'numeric_comparison': 16, 'mathematical_comparison': 17, 'qualitative_property_multihop_retrieval': 18, 'qualitative_comparison': 19, 'numeric_retrieval': 20, 'correlation': 21, 'superlative': 22, 'arithmetic': 23, 'definitional': 24, 'datetime_comparison': 25, 'median': 26, 'datetime_retrieval': 27}\n"
          ]
        }
      ],
      "source": [
        "# Convert the label strings to integers so PyTorch can use them\n",
        "\n",
        "# make a dict from the set of labels - {label:int} pairs\n",
        "label_to_int = {label:idx for idx,label in enumerate(set(all_labels))}\n",
        "int_to_label = {v: k for k, v in label_to_int.items()} # inverse the dict for later\n",
        "\n",
        "integer_labels = [label_to_int[x] for x in all_labels]\n",
        "assert(len(integer_labels) == len(all_labels))\n",
        "\n",
        "print(label_to_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NmJaekTTDJt"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into train/val/test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splits dataset 70/30 for training/testing, then splits the 30 part 50/50 into validation/test sets.\n",
        "X_train, X_almost_test, y_train, y_almost_test = train_test_split(all_questions, integer_labels, test_size=0.3, random_state=0, stratify=integer_labels)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_almost_test, y_almost_test, test_size=0.5, random_state=0, stratify=y_almost_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tv-0Ru93Vulc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddaffc37-871f-46fb-fb83-3d1f51d5dd39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Initialize the tokenizer and read in the data\n",
        "# model_name = \"bert-base-uncased\"\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
        "\n",
        "# Encode the data\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
        "valid_encodings = tokenizer(X_valid, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(X_test, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChPjUP6FXF1s"
      },
      "outputs": [],
      "source": [
        "# Build the dataset object\n",
        "class ATCDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = ATCDataset(train_encodings, y_train) #training data\n",
        "val_dataset = ATCDataset(valid_encodings, y_valid)   #validation set\n",
        "test_dataset = ATCDataset(test_encodings, y_test)    #test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHUQn69tNLHq",
        "outputId": "5aff382c-140a-4692-ee88-298ab6e42ffc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Train the model\n",
        "training_args = TrainingArguments(   # TrainingArguments is from transformers\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=20,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay (original: 0.01)\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=100,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "training_args.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsJ0ac9cl94o"
      },
      "outputs": [],
      "source": [
        "# metrics\n",
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "def compute_metrics(eval_pred):\n",
        "    metric0 = load_metric(\"accuracy\")\n",
        "    metric1 = load_metric(\"precision\")\n",
        "    metric2 = load_metric(\"recall\")\n",
        "    \n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = metric0.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "    # precision = metric1.compute(predictions=predictions, references=labels, average=None)[\"precision\"]\n",
        "    # recall = metric2.compute(predictions=predictions, references=labels, average=None)[\"recall\"]\n",
        "    # return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall}\n",
        "    return {\"accuracy\": accuracy}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teDPMBcScves",
        "outputId": "69cfd543-b9bb-48ef-e74b-adc90c552401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoConfig\n",
        "config = AutoConfig.from_pretrained(model_name) # https://stackoverflow.com/questions/66148641/changing-config-and-loading-hugging-face-model-fine-tuned-on-a-downstream-task#:~:text=bert%2Dbase%2Dcased%22-,config%20%3D%20AutoConfig,-.from_pretrained(pretrained_model_name)%0A%0Aid2label\n",
        "config.label2id = label_to_int\n",
        "config.id2label = int_to_label\n",
        "\n",
        "# model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=len(label_to_int))\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_name, config=config)\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,             # evaluation dataset\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N4QZnkzTc_mz",
        "outputId": "4b8adf50-a0a6-4329-fdfa-a6240335ab34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 600\n",
            "  Num Epochs = 20\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 760\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='760' max='760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [760/760 02:08, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.313643</td>\n",
              "      <td>0.046512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.215835</td>\n",
              "      <td>0.124031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.280100</td>\n",
              "      <td>3.077688</td>\n",
              "      <td>0.124031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.280100</td>\n",
              "      <td>2.889818</td>\n",
              "      <td>0.139535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.280100</td>\n",
              "      <td>2.607770</td>\n",
              "      <td>0.294574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.855200</td>\n",
              "      <td>2.313662</td>\n",
              "      <td>0.434109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.855200</td>\n",
              "      <td>1.996064</td>\n",
              "      <td>0.550388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.935500</td>\n",
              "      <td>1.673851</td>\n",
              "      <td>0.604651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.935500</td>\n",
              "      <td>1.443910</td>\n",
              "      <td>0.620155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.935500</td>\n",
              "      <td>1.252007</td>\n",
              "      <td>0.689922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.838900</td>\n",
              "      <td>1.144749</td>\n",
              "      <td>0.720930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.838900</td>\n",
              "      <td>1.129337</td>\n",
              "      <td>0.705426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.838900</td>\n",
              "      <td>1.172350</td>\n",
              "      <td>0.689922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>1.253351</td>\n",
              "      <td>0.728682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>1.253260</td>\n",
              "      <td>0.705426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.032900</td>\n",
              "      <td>1.277566</td>\n",
              "      <td>0.720930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.032900</td>\n",
              "      <td>1.301163</td>\n",
              "      <td>0.720930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.032900</td>\n",
              "      <td>1.309258</td>\n",
              "      <td>0.728682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.012900</td>\n",
              "      <td>1.314208</td>\n",
              "      <td>0.713178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.012900</td>\n",
              "      <td>1.319850</td>\n",
              "      <td>0.713178</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Configuration saved in ./results/checkpoint-500/config.json\n",
            "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=760, training_loss=1.2050063129318387, metrics={'train_runtime': 128.447, 'train_samples_per_second': 93.424, 'train_steps_per_second': 5.917, 'total_flos': 108715047840000.0, 'train_loss': 1.2050063129318387, 'epoch': 20.0})"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "UmMueoIFnmIw",
        "outputId": "81f12d2e-0861-42c5-f40d-c98cf0e1e660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 20.0,\n",
              " 'eval_accuracy': 0.7131782945736435,\n",
              " 'eval_loss': 1.3198504447937012,\n",
              " 'eval_runtime': 0.9724,\n",
              " 'eval_samples_per_second': 132.665,\n",
              " 'eval_steps_per_second': 3.085}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# Evaluate model on the VALIDATION dataset\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "bTFbVAgfpXMJ",
        "outputId": "002bbd3e-c4c7-4aa5-aea4-129ad919423e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Evaluate the model on the TEST dataset\n",
        "output = trainer.predict(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeUJg56yqkov",
        "outputId": "df7d55d8-7845-478a-93c7-86f567b48900"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_accuracy': 0.8062015503875969,\n",
              " 'test_loss': 0.854979395866394,\n",
              " 'test_runtime': 0.9337,\n",
              " 'test_samples_per_second': 138.158,\n",
              " 'test_steps_per_second': 3.213}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "output.metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ANALYZE OUTPUTS\n",
        "# ideas:\n",
        "# - see which classes do good/bad (output to csv and look at it. Also do calculations, see % correct)\n",
        "# - train for longer (more epochs)\n",
        "# - train on fewer classes (just our favorites)\n",
        "# - also do Naive Bayes again for comparison\n",
        "\n",
        "#*** IMPORTANT!!\n",
        "# it's possible that our classes are too similar to distinguish.\n",
        "# - you should train on parent classes. Then train separate classifiers for each.\n",
        "# - do this. it's a good idea."
      ],
      "metadata": {
        "id": "fPHx2Qbg2yHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add predicted labels to the test set in a new column. Then export as a new csv.\n",
        "all_encodings = tokenizer(all_questions, truncation=True, padding=True)\n",
        "whole_dataset =  ATCDataset(all_encodings, integer_labels)  #FOR TESTING ON ALL DATA\n",
        "\n",
        "# predictionOutput = trainer.predict(whole_dataset) # this is a PredictionOutput object\n",
        "\n",
        "# https://stackoverflow.com/a/69374378\n",
        "from scipy.special import softmax\n",
        "from numpy import argmax\n",
        "\n",
        "# whole_dataset\n",
        "prediction_logits = trainer.predict(val_dataset).predictions # get raw model outputs from PredictionOutput object\n",
        "\n",
        "# you can softmax the logits first, but it makes no difference when producing a single label\n",
        "predictions = argmax(prediction_logits, axis=1)\n",
        "predicted_labels = [int_to_label[p] for p in predictions]\n",
        "\n",
        "# save predictions as column in new csv file (this works)\n",
        "\n",
        "\n",
        "# new_df = pd.DataFrame([X_valid, y_valid])\n",
        "val_labels_str = [int_to_label[p] for p in y_valid]\n",
        "new_df = pd.DataFrame(list(zip(X_valid, val_labels_str)),\n",
        "                      columns =['questions', 'best_guess_label'])\n",
        "\n",
        "# #new_df = labeledData\n",
        "new_df['predictions'] = predicted_labels\n",
        "# #https://datascience.stackexchange.com/a/30993\n",
        "new_df['correct'] = new_df['predictions']==new_df[labelColumn]\n",
        "new_df['correct_viz'] = new_df['correct'].map({True: '✅', False: '❌'})\n",
        "new_df.to_csv('/content/xdrive/MyDrive/qcat_huggingface/predictions_debug.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "oRgd5bJ6EaDN",
        "outputId": "7a371e7e-0cbd-453d-e638-8b552ae3aa88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 129\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:43]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "_b0rhNV_7VNH",
        "outputId": "47ffe593-9dac-4422-97dc-41d2e0732941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             questions  \\\n",
              "55   How many total yards did JaMarcus Russell's co...   \n",
              "40                       what did emily bronte die of?   \n",
              "19                       what is the biggest mountain?   \n",
              "31       show me the flights from cleveland to memphis   \n",
              "114             Which are the best engineering fields?   \n",
              "56                     all members of the royal family   \n",
              "69                              who is richard feynman   \n",
              "105  How long can raw and cooked sausage last refri...   \n",
              "81   When can I expect my Cognizant confirmation mail?   \n",
              "26   which states are south of the iowa line but no...   \n",
              "\n",
              "                   best_guess_label                     predictions  correct  \\\n",
              "55                       arithmetic               numeric_retrieval    False   \n",
              "40   qualitative_property_retrieval  qualitative_property_retrieval     True   \n",
              "19                      superlative                     superlative     True   \n",
              "31        set_property_satisfaction       set_property_satisfaction     True   \n",
              "114                         opinion                         opinion     True   \n",
              "56                    set_retrieval                   set_retrieval     True   \n",
              "69                     definitional  qualitative_property_retrieval    False   \n",
              "105               numeric_retrieval                        counting    False   \n",
              "81               datetime_retrieval              datetime_retrieval     True   \n",
              "26                 set_intersection                       set_union    False   \n",
              "\n",
              "    correct_viz  \n",
              "55            ❌  \n",
              "40            ✅  \n",
              "19            ✅  \n",
              "31            ✅  \n",
              "114           ✅  \n",
              "56            ✅  \n",
              "69            ❌  \n",
              "105           ❌  \n",
              "81            ✅  \n",
              "26            ❌  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c43eba72-20d9-4f68-9e53-09dfdb3228e4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions</th>\n",
              "      <th>best_guess_label</th>\n",
              "      <th>predictions</th>\n",
              "      <th>correct</th>\n",
              "      <th>correct_viz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>How many total yards did JaMarcus Russell's co...</td>\n",
              "      <td>arithmetic</td>\n",
              "      <td>numeric_retrieval</td>\n",
              "      <td>False</td>\n",
              "      <td>❌</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>what did emily bronte die of?</td>\n",
              "      <td>qualitative_property_retrieval</td>\n",
              "      <td>qualitative_property_retrieval</td>\n",
              "      <td>True</td>\n",
              "      <td>✅</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>what is the biggest mountain?</td>\n",
              "      <td>superlative</td>\n",
              "      <td>superlative</td>\n",
              "      <td>True</td>\n",
              "      <td>✅</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>show me the flights from cleveland to memphis</td>\n",
              "      <td>set_property_satisfaction</td>\n",
              "      <td>set_property_satisfaction</td>\n",
              "      <td>True</td>\n",
              "      <td>✅</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>Which are the best engineering fields?</td>\n",
              "      <td>opinion</td>\n",
              "      <td>opinion</td>\n",
              "      <td>True</td>\n",
              "      <td>✅</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>all members of the royal family</td>\n",
              "      <td>set_retrieval</td>\n",
              "      <td>set_retrieval</td>\n",
              "      <td>True</td>\n",
              "      <td>✅</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>who is richard feynman</td>\n",
              "      <td>definitional</td>\n",
              "      <td>qualitative_property_retrieval</td>\n",
              "      <td>False</td>\n",
              "      <td>❌</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>How long can raw and cooked sausage last refri...</td>\n",
              "      <td>numeric_retrieval</td>\n",
              "      <td>counting</td>\n",
              "      <td>False</td>\n",
              "      <td>❌</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>When can I expect my Cognizant confirmation mail?</td>\n",
              "      <td>datetime_retrieval</td>\n",
              "      <td>datetime_retrieval</td>\n",
              "      <td>True</td>\n",
              "      <td>✅</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>which states are south of the iowa line but no...</td>\n",
              "      <td>set_intersection</td>\n",
              "      <td>set_union</td>\n",
              "      <td>False</td>\n",
              "      <td>❌</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c43eba72-20d9-4f68-9e53-09dfdb3228e4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c43eba72-20d9-4f68-9e53-09dfdb3228e4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c43eba72-20d9-4f68-9e53-09dfdb3228e4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a report: for each question type, what percent are correct?\n",
        "\n",
        "print(\"____________% of validation dataset labeled correctly____________\")\n",
        "for label in set(all_labels):   # loop over question types\n",
        "    cur_df = new_df.loc[new_df[labelColumn] == label] # get df rows of that type\n",
        "    total = len(cur_df)\n",
        "    try:\n",
        "        num_correct = cur_df[\"correct\"].value_counts()[True]  # if correct, add to total\n",
        "    except :\n",
        "        num_correct = 0     #catch error if none are true\n",
        "    \n",
        "    print( \"{: <40} {: >10} {: >10}\".format(*[label, f\"{num_correct}/{total}\", round(num_correct/total, 2)]) )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfivClNLpLMq",
        "outputId": "5474169b-df74-4d4a-e147-d13dc9edd29e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "____________% of validation dataset labeled correctly____________\n",
            "correlation                                     0/1        0.0\n",
            "causal_explanation                              4/6       0.67\n",
            "boolean_and                                     2/5        0.4\n",
            "mode                                            3/3        1.0\n",
            "superlative                                     7/8       0.88\n",
            "opinion                                         4/9       0.44\n",
            "set_difference                                  1/1        1.0\n",
            "set_retrieval                                   1/2        0.5\n",
            "datetime_retrieval                              3/4       0.75\n",
            "datetime_comparison                             2/3       0.67\n",
            "median                                          2/2        1.0\n",
            "definitional                                    2/3       0.67\n",
            "boolean_retrieval                               7/7        1.0\n",
            "qualitative_property_retrieval                13/16       0.81\n",
            "qualitative_property_multihop_retrieval         2/3       0.67\n",
            "range                                           2/2        1.0\n",
            "numeric_comparison                              1/1        1.0\n",
            "numeric_retrieval                               5/5        1.0\n",
            "arithmetic                                      2/4        0.5\n",
            "mathematical_comparison                         2/2        1.0\n",
            "set_property_satisfaction                       5/6       0.83\n",
            "counting                                        1/2        0.5\n",
            "average                                         2/2        1.0\n",
            "set_intersection                                0/2        0.0\n",
            "qualitative_comparison                          3/3        1.0\n",
            "standard_deviation                              2/3       0.67\n",
            "set_union                                       3/3        1.0\n",
            "boolean_or                                      5/5        1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-CLJ0sErMCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "211a89cf-123c-47a4-dac9-cbe667ff3e7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in /content/xdrive/MyDrive/qcat_huggingface/pretrained_model/config.json\n",
            "Model weights saved in /content/xdrive/MyDrive/qcat_huggingface/pretrained_model/pytorch_model.bin\n",
            "Saving model checkpoint to /content/xdrive/MyDrive/qcat_huggingface/pretrained_trainer/\n",
            "Configuration saved in /content/xdrive/MyDrive/qcat_huggingface/pretrained_trainer/config.json\n",
            "Model weights saved in /content/xdrive/MyDrive/qcat_huggingface/pretrained_trainer/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "# Save the model\n",
        "\n",
        "#save tokenizer? https://stackoverflow.com/a/64552678\n",
        "\n",
        "path = \"/content/xdrive/MyDrive/qcat_huggingface/\"\n",
        "model.save_pretrained(path + \"pretrained_model/\")\n",
        "trainer.save_model(path + \"pretrained_trainer/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the saved model and test some input string\n",
        "# https://github.com/huggingface/transformers/issues/7849#issuecomment-709995286\n",
        "from transformers import TextClassificationPipeline, BertConfig\n",
        "\n",
        "# load config file: https://huggingface.co/transformers/v2.9.1/main_classes/configuration.html\n",
        "# https://huggingface.co/transformers/v2.9.1/main_classes/configuration.html#transformers.PretrainedConfig.from_pretrained\n",
        "\n",
        "# load model\n",
        "model = DistilBertForSequenceClassification.from_pretrained(path+\"pretrained_model/\", num_labels=len(label_to_int), local_files_only=True, id2label=int_to_label, label2id=label_to_int)\n",
        "\n",
        "# classifier pipeline\n",
        "# https://discuss.huggingface.co/t/i-have-trained-my-classifier-now-how-do-i-do-predictions/3625/2\n",
        "\n",
        "\n",
        "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True)\n",
        "# outputs a list of dicts like [[{'label': 'NEGATIVE', 'score': 0.0001223755971295759},  {'label': 'POSITIVE', 'score': 0.9998776316642761}]]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUO489VbbHdb",
        "outputId": "4349ce23-e65f-42f9-b664-fd3e694e0f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/xdrive/MyDrive/qcat_huggingface/pretrained_model/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"correlation\",\n",
            "    \"1\": \"causal_explanation\",\n",
            "    \"2\": \"boolean_and\",\n",
            "    \"3\": \"mode\",\n",
            "    \"4\": \"superlative\",\n",
            "    \"5\": \"opinion\",\n",
            "    \"6\": \"set_difference\",\n",
            "    \"7\": \"set_retrieval\",\n",
            "    \"8\": \"datetime_retrieval\",\n",
            "    \"9\": \"datetime_comparison\",\n",
            "    \"10\": \"median\",\n",
            "    \"11\": \"definitional\",\n",
            "    \"12\": \"boolean_retrieval\",\n",
            "    \"13\": \"qualitative_property_retrieval\",\n",
            "    \"14\": \"qualitative_property_multihop_retrieval\",\n",
            "    \"15\": \"range\",\n",
            "    \"16\": \"numeric_comparison\",\n",
            "    \"17\": \"numeric_retrieval\",\n",
            "    \"18\": \"arithmetic\",\n",
            "    \"19\": \"mathematical_comparison\",\n",
            "    \"20\": \"set_property_satisfaction\",\n",
            "    \"21\": \"counting\",\n",
            "    \"22\": \"average\",\n",
            "    \"23\": \"set_intersection\",\n",
            "    \"24\": \"qualitative_comparison\",\n",
            "    \"25\": \"standard_deviation\",\n",
            "    \"26\": \"set_union\",\n",
            "    \"27\": \"boolean_or\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"arithmetic\": 18,\n",
            "    \"average\": 22,\n",
            "    \"boolean_and\": 2,\n",
            "    \"boolean_or\": 27,\n",
            "    \"boolean_retrieval\": 12,\n",
            "    \"causal_explanation\": 1,\n",
            "    \"correlation\": 0,\n",
            "    \"counting\": 21,\n",
            "    \"datetime_comparison\": 9,\n",
            "    \"datetime_retrieval\": 8,\n",
            "    \"definitional\": 11,\n",
            "    \"mathematical_comparison\": 19,\n",
            "    \"median\": 10,\n",
            "    \"mode\": 3,\n",
            "    \"numeric_comparison\": 16,\n",
            "    \"numeric_retrieval\": 17,\n",
            "    \"opinion\": 5,\n",
            "    \"qualitative_comparison\": 24,\n",
            "    \"qualitative_property_multihop_retrieval\": 14,\n",
            "    \"qualitative_property_retrieval\": 13,\n",
            "    \"range\": 15,\n",
            "    \"set_difference\": 6,\n",
            "    \"set_intersection\": 23,\n",
            "    \"set_property_satisfaction\": 20,\n",
            "    \"set_retrieval\": 7,\n",
            "    \"set_union\": 26,\n",
            "    \"standard_deviation\": 25,\n",
            "    \"superlative\": 4\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file /content/xdrive/MyDrive/qcat_huggingface/pretrained_model/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
            "\n",
            "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at /content/xdrive/MyDrive/qcat_huggingface/pretrained_model/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answers = pipe(\"when was Elon Musk born?\")\n",
        "answers\n",
        "\n",
        "# prediction_logits = pipe(\"I love this movie!\")\n",
        "\n",
        "# # you can softmax the logits first, but it makes no difference when producing a single label\n",
        "# prediction = argmax(prediction_logits, axis=1)\n",
        "# predicted_label = int_to_label[p]\n",
        "# predicted_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-e86LKgft3v",
        "outputId": "74f72205-979d-40f1-bef3-20fd9e27752b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': 'correlation', 'score': 0.00019069426343776286},\n",
              "  {'label': 'causal_explanation', 'score': 0.0006956280558370054},\n",
              "  {'label': 'boolean_and', 'score': 0.00017970586486626416},\n",
              "  {'label': 'mode', 'score': 0.00011937258386751637},\n",
              "  {'label': 'superlative', 'score': 0.00047503397217951715},\n",
              "  {'label': 'opinion', 'score': 0.00020326283993199468},\n",
              "  {'label': 'set_difference', 'score': 0.0001147850343841128},\n",
              "  {'label': 'set_retrieval', 'score': 0.00012628895638044924},\n",
              "  {'label': 'datetime_retrieval', 'score': 0.9931279420852661},\n",
              "  {'label': 'datetime_comparison', 'score': 0.00048031439655460417},\n",
              "  {'label': 'median', 'score': 0.00015297251229640096},\n",
              "  {'label': 'definitional', 'score': 0.00013775295519735664},\n",
              "  {'label': 'boolean_retrieval', 'score': 0.0002684938081074506},\n",
              "  {'label': 'qualitative_property_retrieval', 'score': 0.0007812971016392112},\n",
              "  {'label': 'qualitative_property_multihop_retrieval',\n",
              "   'score': 0.0003690363955684006},\n",
              "  {'label': 'range', 'score': 6.378563557518646e-05},\n",
              "  {'label': 'numeric_comparison', 'score': 0.00026257996796630323},\n",
              "  {'label': 'numeric_retrieval', 'score': 0.00033546335180290043},\n",
              "  {'label': 'arithmetic', 'score': 0.0006642364314757288},\n",
              "  {'label': 'mathematical_comparison', 'score': 0.000153510452946648},\n",
              "  {'label': 'set_property_satisfaction', 'score': 0.0002872233744710684},\n",
              "  {'label': 'counting', 'score': 0.0002814751642290503},\n",
              "  {'label': 'average', 'score': 5.3082821978023276e-05},\n",
              "  {'label': 'set_intersection', 'score': 0.00015765537682455033},\n",
              "  {'label': 'qualitative_comparison', 'score': 9.104991477215663e-05},\n",
              "  {'label': 'standard_deviation', 'score': 6.992980343056843e-05},\n",
              "  {'label': 'set_union', 'score': 9.38035300350748e-05},\n",
              "  {'label': 'boolean_or', 'score': 6.367970490828156e-05}]]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Question_Type_Classifier_Huggingface_Ours.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}